{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Desarrollo "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Librerias\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import sklearn.model_selection\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from ignite.engine import  Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from codes import utils\n",
    "from codes import metric as mt\n",
    "from codes.dataset2 import WetSoundDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid\n",
    "from codes.models import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rm -rf ./tmp/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Importación y pre-procesamiento del dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "N_FOLDS = 4\n",
    "AUDIO_DIR = \"features/train_set/\"\n",
    "SAMPLE_RATE = 44100\n",
    "LEN_SEC = 300\n",
    "LEN_SAMPLES = LEN_SEC*SAMPLE_RATE\n",
    "NUM_SAMPLES = 1292   #Cantidad de secuencias , no largo de secuencia 12920/40\n",
    "__class_labels = {\n",
    "'perro'    : 0,\n",
    "'rana'     : 1,\n",
    "'lluvia'   : 2,\n",
    "'motor'    : 3,\n",
    "'ave'      : 4\n",
    "}\n",
    "N_FFT = 2048\n",
    "HOP = int(N_FFT/2)\n",
    "N_MELS = 40\n",
    "LEN_MBE = round(LEN_SAMPLES/int(HOP*NUM_SAMPLES))\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device {device}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataloaders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "wet = WetSoundDataset(AUDIO_DIR,\n",
    "                        LEN_MBE,\n",
    "                        NUM_SAMPLES,\n",
    "                        __class_labels,\n",
    "                        device)\n",
    "print(f\"There are {len(wet)} samples in the dataset.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 5760 samples in the dataset.\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SEDnet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = SEDnet(n_class=len(__class_labels))\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SEDnet(\n",
      "  (CNN1): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(1, 5), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=True)\n",
      "  )\n",
      "  (CNN2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=True)\n",
      "  )\n",
      "  (CNN3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=True)\n",
      "  )\n",
      "  (RNN): Sequential(\n",
      "    (0): GRU(256, 32, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (1): SelectItem()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): GRU(64, 32, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (4): SelectItem()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (FC): Sequential(\n",
      "    (0): TimeDistributed(\n",
      "      (module): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): TimeDistributed(\n",
      "      (module): Linear(in_features=32, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/vpoblete/miniconda3/envs/ia_257/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Entrenamiento de la red convolucional"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from ignite.engine import  Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "max_epochs = 500"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "# K-fold Cross Validation model evaluation\n",
    "%tensorboard --logdir logs/fit\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(wet)):\n",
    "    torch.manual_seed(12345) # Inicialización\n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    kfold_trainset = Subset(wet,train_ids)\n",
    "    kfold_valset = Subset(wet, val_ids)\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "                    kfold_trainset, \n",
    "                    batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(\n",
    "                    kfold_valset,\n",
    "                    batch_size=64,shuffle=False)\n",
    "    display(len(trainloader),len(valloader))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = SEDnet(n_class=len(__class_labels))\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = 1e-3)\n",
    "    criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "    metrics_torch = {\n",
    "        'Accuracy':Accuracy(output_transform=mt.thresholded_output_transform),\n",
    "        'Loss':Loss(criterion,output_transform=mt.thresholded_output_transform),\n",
    "        'Err':mt.er_rate(output_transform=mt.thresholded_output_transform),\n",
    "        'F1':mt.f1_score(output_transform=mt.thresholded_output_transform),\n",
    "    }\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=metrics_torch, device=device)\n",
    "    valid_evaluator = create_supervised_evaluator(model, metrics=metrics_torch, device=device)\n",
    "    # Contexto de escritura de datos para tensorboard\n",
    "    #tensorboard --logdir=/tmp/tensorboard\n",
    "    \n",
    "    with SummaryWriter(log_dir=f'logs/fit/tensorboard/SEDnet_kfold{fold+1}') as writer:\n",
    "\n",
    "        @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 1 epocas\n",
    "        def log_results(engine):\n",
    "            # Evaluo el conjunto de entrenamiento\n",
    "            train_evaluator.run(trainloader) \n",
    "            writer.add_scalar(\"train/er\", train_evaluator.state.metrics['Err'], engine.state.epoch)\n",
    "            writer.add_scalar(\"train/f1\", train_evaluator.state.metrics['F1'], engine.state.epoch)\n",
    "            writer.add_scalar(\"train/loss\", train_evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "            writer.add_scalar(\"train/acc\", train_evaluator.state.metrics['Accuracy'], engine.state.epoch)\n",
    "            \n",
    "            # Evaluo el conjunto de validación\n",
    "            valid_evaluator.run(valloader) \n",
    "            er = valid_evaluator.state.metrics['Err']\n",
    "            f1 = valid_evaluator.state.metrics['F1']\n",
    "            acc = valid_evaluator.state.metrics['Loss']\n",
    "            loss = valid_evaluator.state.metrics['Accuracy']\n",
    "            writer.add_scalar(\"valid/er\", er, engine.state.epoch)\n",
    "            writer.add_scalar(\"valid/f1\", f1, engine.state.epoch)\n",
    "            writer.add_scalar(\"valid/loss\", acc, engine.state.epoch)\n",
    "            writer.add_scalar(\"valid/acc\", loss, engine.state.epoch)\n",
    "\n",
    "        def score_function(engine):\n",
    "            val_loss = engine.state.metrics['Err']\n",
    "            return -val_loss\n",
    "\n",
    "        handler = EarlyStopping(patience=100, score_function=score_function, trainer=trainer)\n",
    "\n",
    "        # Guardo el mejor modelo en validación\n",
    "        best_model_handler = ModelCheckpoint(dirname='models/', require_empty=False, filename_prefix=\"best\", n_saved=1,\n",
    "                                             score_function=lambda engine: -engine.state.metrics['Err'],\n",
    "                                             score_name=\"val_error\")\n",
    "\n",
    "        # Lo siguiente se ejecuta cada ves que termine el loop de validación\n",
    "        valid_evaluator.add_event_handler(Events.COMPLETED, \n",
    "                                    best_model_handler, {'SEDnet{}'.format(fold): model})\n",
    "        valid_evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "        trainer.run(trainloader, max_epochs=max_epochs)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20520), started 0:30:18 ago. (Use '!kill 20520' to kill it.)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-14e66638f8631746\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-14e66638f8631746\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'threshold'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b919a4091593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEDnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__class_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'threshold'"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('ia_257': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "2c2ae1fa8f4c727dd589fb2bff9478f53eaab7b86ff56190838baa3205820518"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}