{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Librerias\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import sklearn.model_selection\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from ignite.engine import  Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, Metric, ClassificationReport\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from codes import utils,metrics\n",
    "from sklearn import metrics as mt\n",
    "from codes.sed_models import SEDnet\n",
    "from codes.dataset2 import WetSoundDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "AUDIO_DIR = \"features/test_set/\"\n",
    "SAMPLE_RATE = 44100\n",
    "LEN_SEC = 300\n",
    "LEN_SAMPLES = LEN_SEC*SAMPLE_RATE\n",
    "NUM_SAMPLES = 323  #Cantidad de secuencias , no largo de secuencia 12920/40\n",
    "__class_labels = {\n",
    "'perro'    : 0,\n",
    "'rana'     : 1,\n",
    "'lluvia'   : 2,\n",
    "'motor'    : 3,\n",
    "'ave'      : 4\n",
    "}\n",
    "N_FFT = 2048\n",
    "HOP = int(N_FFT/2)\n",
    "N_MELS = 40\n",
    "LEN_MBE = round(LEN_SAMPLES/int(HOP*NUM_SAMPLES))\n",
    "frames_1_sec = int(SAMPLE_RATE/(N_FFT/2.0))\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device {device}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "wet = WetSoundDataset(AUDIO_DIR,\n",
    "                        LEN_MBE,\n",
    "                        NUM_SAMPLES,\n",
    "                        __class_labels,\n",
    "                        device)\n",
    "print(f\"There are {len(wet)} samples in the dataset.\")\n",
    "test_loader = DataLoader(wet, shuffle=False, batch_size=90)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 5760 samples in the dataset.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cargar modelos entrenados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "path_models = \"models/\"\n",
    "results = dict()\n",
    "for fold_model in os.listdir(path_models):\n",
    "    filter_file = fold_model.split(\".\")\n",
    "    if len(filter_file)>1:\n",
    "        if filter_file[2]==\"pt\":\n",
    "            print(fold_model)\n",
    "            model = SEDnet(len(__class_labels))\n",
    "            model.load_state_dict(torch.load(path_models+fold_model))\n",
    "            model.to(device)\n",
    "\n",
    "            pred = list()\n",
    "            targets = list()\n",
    "            i=0\n",
    "            for data,label in test_loader:\n",
    "                with torch.no_grad():\n",
    "                    pred_i = model.forward(data)\n",
    "                label = label.to('cpu')\n",
    "                pred_i = pred_i.to('cpu')\n",
    "                pred_i,label = sed_metrics.thresholded_output_transform([pred_i,label])\n",
    "                targets.append(label)\n",
    "                pred.append(pred_i)\n",
    "                del pred_i\n",
    "                del data\n",
    "                del label\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            pred = torch.stack(pred)\n",
    "            pred = pred.view(pred.shape[1]*pred.shape[0]*pred.shape[2],pred.shape[3])\n",
    "            pred = pred.numpy()\n",
    "            targets = torch.stack(targets)\n",
    "            targets = targets.view(targets.shape[1]*targets.shape[0]*targets.shape[2],targets.shape[3])\n",
    "            targets = targets.numpy()\n",
    "\n",
    "            metrics_data = metrics.compute_scores_orig(pred, targets,frames_1_sec)\n",
    "\n",
    "            results[fold_model]=metrics_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_SEDnet0_val_error=-0.2139.pt\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/vpoblete/miniconda3/envs/ia_257/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/vpoblete/miniconda3/envs/ia_257/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_SEDnet1_val_error=-0.2272.pt\n",
      "best_SEDnet3_val_error=-0.2135.pt\n",
      "best_SEDnet2_val_error=-0.2111.pt\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'best_SEDnet0_val_error=-0.2139.pt': {'f1_overall_1sec': 0.74,\n",
       "  'er_overall_1sec': 0.51},\n",
       " 'best_SEDnet1_val_error=-0.2272.pt': {'f1_overall_1sec': 0.74,\n",
       "  'er_overall_1sec': 0.48},\n",
       " 'best_SEDnet3_val_error=-0.2135.pt': {'f1_overall_1sec': 0.75,\n",
       "  'er_overall_1sec': 0.51},\n",
       " 'best_SEDnet2_val_error=-0.2111.pt': {'f1_overall_1sec': 0.74,\n",
       "  'er_overall_1sec': 0.52}}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "257",
   "language": "python",
   "name": "257"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}